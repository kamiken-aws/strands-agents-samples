{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Strands Agentsãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®é«˜åº¦ãªå‡¦ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strands Agentsã§ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œä¸­ã«ç™ºç”Ÿã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‚å—ã—ã¦å‡¦ç†ã™ã‚‹ãŸã‚ã®2ã¤ã®æ–¹æ³•ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ï¼š\n",
    "    \n",
    "- **éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿**: FastAPIã€aiohttpã€Django Channelsãªã©ã®éåŒæœŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«æœ€é©ã§ã™ã€‚ã“ã‚Œã‚‰ã®ç’°å¢ƒã§ã¯ã€SDKã¯éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’è¿”ã™`stream_async`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚\n",
    "- **ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œä¸­ã«ç™ºç”Ÿã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‚å—ã—ã¦å‡¦ç†ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã€ã‚«ã‚¹ã‚¿ãƒ å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ä¾‹ã§ã¯ã€ä¸¡æ–¹ã®æ–¹æ³•ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®å‘¼ã³å‡ºã—ã‚’å‡¦ç†ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™\n",
    "\n",
    "\n",
    "## ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©³ç´°\n",
    "<div style=\"float: left; margin-right: 20px; \">\n",
    "    \n",
    "|æ©Ÿèƒ½                |èª¬æ˜                                        |\n",
    "|--------------------|-------------------------------------------|\n",
    "|ä½¿ç”¨ã™ã‚‹æ©Ÿèƒ½         |éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©         |\n",
    "|ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ§‹é€      |ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£              |\n",
    "|ä½¿ç”¨ã™ã‚‹ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ„ãƒ¼ãƒ«   |calculator                           |\n",
    "|ä½œæˆã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«|å¤©æ°—äºˆå ±                                   |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n",
    "\n",
    "<div style=\"text-align:left;\">\n",
    "    <img src=\"images/architecture.png\" width=\"65%\" />\n",
    "</div>\n",
    "\n",
    "## ä¸»ãªæ©Ÿèƒ½\n",
    "* ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿\n",
    "* ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©\n",
    "\n",
    "\n",
    "## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨å‰ææ¡ä»¶\n",
    "\n",
    "### å‰ææ¡ä»¶\n",
    "* Python 3.10ä»¥ä¸Š\n",
    "* AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "* Amazon Bedrockã§Anthropic Claude 3.7ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "\n",
    "ãã‚Œã§ã¯ã€Strands Agent Agentã«å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ã‚‡ã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing pre-requisites\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "\n",
    "ãã‚Œã§ã¯ã€ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ã‚‡ã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import httpx\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import StreamingResponse\n",
    "from pydantic import BaseModel\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ–¹æ³•1 - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strands Agentsã¯ã€`stream_async`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é€šã˜ã¦éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã®ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã—ã€Webã‚µãƒ¼ãƒãƒ¼ã€APIã€ãã®ä»–ã®éåŒæœŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã®éåŒæœŸç’°å¢ƒã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ä¾‹ã‚’ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ç´¹ä»‹ã—ã¦ã„ã‚‹ãŸã‚ã€`asyncio.run`ã¨`loop.run_until_complete`ã®ãƒã‚¹ãƒˆã•ã‚ŒãŸä½¿ç”¨ã‚’è¨±å¯ã™ã‚‹ãŸã‚ã«`nest_asyncio`ã‚’é©ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stream_asyncã‚’ä½¿ç”¨ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆã¨å‘¼ã³å‡ºã—\n",
    "\n",
    "ãã‚Œã§ã¯ã€çµ„ã¿è¾¼ã¿calculatorãƒ„ãƒ¼ãƒ«ã¨`callback_handler`ãªã—ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ã€‚`stream_async`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆã‚’åå¾©å‡¦ç†ã—ã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our agent without a callback handler\n",
    "agent = Agent(\n",
    "    model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",  # Optional: Specify the model ID\n",
    "    tools=[calculator], \n",
    "    callback_handler=None)\n",
    "\n",
    "# Async function that iterators over streamed agent events\n",
    "\n",
    "\n",
    "async def process_streaming_response():\n",
    "    agent_stream = agent.stream_async(\"Calculate 2+2\")\n",
    "    async for event in agent_stream:\n",
    "        print(event)\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "asyncio.run(process_streaming_response())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã®è¿½è·¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®ä¾‹ã¯ã€ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã¨ã€ã‚¤ãƒ™ãƒ³ãƒˆãŒäº’ã„ã«ã©ã®ã‚ˆã†ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚Strands Agentã§ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’ç†è§£ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ï¼š\n",
    "\n",
    "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚ˆã‚Šé©åˆ‡ã«åˆ†æã™ã‚‹ãŸã‚ã«ã€å°åˆ·ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ã€‚åŒã˜ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å¼•ãç¶šãä½¿ç”¨ã—ã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Async function that iterators over streamed agent events\n",
    "\n",
    "\n",
    "async def process_streaming_response():\n",
    "    agent_stream = agent.stream_async(\"What is the capital of France and what is 42+7?\")\n",
    "    async for event in agent_stream:\n",
    "        # Track event loop lifecycle\n",
    "        if event.get(\"init_event_loop\", False):\n",
    "            print(\"ğŸ”„ Event loop initialized\")\n",
    "        elif event.get(\"start_event_loop\", False):\n",
    "            print(\"â–¶ï¸ Event loop cycle starting\")\n",
    "        elif event.get(\"start\", False):\n",
    "            print(\"ğŸ“ New cycle started\")\n",
    "        elif \"message\" in event:\n",
    "            print(f\"ğŸ“¬ New message created: {event['message']['role']}\")\n",
    "        elif event.get(\"force_stop\", False):\n",
    "            print(\n",
    "                f\"ğŸ›‘ Event loop force-stopped: {event.get('force_stop_reason', 'unknown reason')}\"\n",
    "            )\n",
    "\n",
    "        # Track tool usage\n",
    "        if \"current_tool_use\" in event and event[\"current_tool_use\"].get(\"name\"):\n",
    "            tool_name = event[\"current_tool_use\"][\"name\"]\n",
    "            print(f\"ğŸ”§ Using tool: {tool_name}\")\n",
    "\n",
    "        # Show only a snippet of text to keep output clean\n",
    "        if \"data\" in event:\n",
    "            # Only show first 20 chars of each chunk for demo purposes\n",
    "            data_snippet = event[\"data\"][:20] + (\n",
    "                \"...\" if len(event[\"data\"]) > 20 else \"\"\n",
    "            )\n",
    "            print(f\"ğŸ“Ÿ Text: {data_snippet}\")\n",
    "\n",
    "    return event[\"result\"]\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "asyncio.run(process_streaming_response())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAPIçµ±åˆ\n",
    "\n",
    "`stream_async`ã‚’FastAPIã¨çµ±åˆã—ã¦ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã®ãŸã‚ã«ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«`weather_forecast`ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ ã—ã¾ã™ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ›´æ–°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™\n",
    "\n",
    "<div style=\"text-align:left;\">\n",
    "    <img src=\"images/architecture_2.png\" width=\"65%\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definition\n",
    "\n",
    "\n",
    "@tool\n",
    "def weather_forecast(city: str, days: int = 3) -> str:\n",
    "    return f\"Weather forecast for {city} for the next {days} days...\"\n",
    "\n",
    "\n",
    "# FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "class PromptRequest(BaseModel):\n",
    "    prompt: str\n",
    "\n",
    "\n",
    "@app.post(\"/stream\")\n",
    "async def stream_response(request: PromptRequest):\n",
    "    async def generate():\n",
    "        agent = Agent(tools=[calculator, weather_forecast], callback_handler=None)\n",
    "        try:\n",
    "            async for event in agent.stream_async(request.prompt):\n",
    "                if \"data\" in event:\n",
    "                    yield event[\"data\"]\n",
    "        except Exception as e:\n",
    "            yield f\"Error: {str(e)}\"\n",
    "\n",
    "    return StreamingResponse(generate(), media_type=\"text/plain\")\n",
    "\n",
    "\n",
    "# Function to start server without blocking\n",
    "\n",
    "\n",
    "async def start_server():\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8001, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "\n",
    "# Run server as background task\n",
    "if \"server_task\" not in globals():\n",
    "    server_task = asyncio.create_task(start_server())\n",
    "    await asyncio.sleep(0.1)  # Give server time to start\n",
    "\n",
    "print(\"âœ… Server is running at http://0.0.0.0:8001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastAPIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‘¼ã³å‡ºã—\n",
    "ãã—ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™ã“ã¨ãŒã§ãã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_stream():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        async with client.stream(\n",
    "            \"POST\",\n",
    "            \"http://0.0.0.0:8001/stream\",\n",
    "            json={\"prompt\": \"What is weather in NYC?\"},\n",
    "        ) as response:\n",
    "            async for line in response.aiter_lines():\n",
    "                if line.strip():  # Skip empty lines\n",
    "                    print(\"Received:\", line)\n",
    "\n",
    "\n",
    "await fetch_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ–¹æ³•2 - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ã¯ã€Strands Agentsã®å¼·åŠ›ãªæ©Ÿèƒ½ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œä¸­ã«ç™ºç”Ÿã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‚å—ã—ã¦å‡¦ç†ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã€ã‚«ã‚¹ã‚¿ãƒ å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ä¸­ã«ç™ºç”Ÿã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å—ä¿¡ã—ã¾ã™ï¼š\n",
    "\n",
    "- ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ\n",
    "- ãƒ„ãƒ¼ãƒ«ã®é¸æŠã¨å®Ÿè¡Œ\n",
    "- æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹\n",
    "- ã‚¨ãƒ©ãƒ¼ã¨å®Œäº†\n",
    "\n",
    "\n",
    "ãã‚Œã§ã¯ã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã¨ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã‚’å¼·èª¿ã™ã‚‹ãŸã‚ã«ã‚¤ãƒ™ãƒ³ãƒˆå…¥åŠ›ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©é–¢æ•°ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ã€‚ãã®ãŸã‚ã«ã€calculatorãƒ„ãƒ¼ãƒ«ã®ã¿ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å†ã³ä½¿ç”¨ã—ã¾ã™\n",
    "\n",
    "<div style=\"text-align:left;\">\n",
    "    <img src=\"images/architecture.png\" width=\"65%\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_callback_handler(**kwargs):\n",
    "    # Process stream data\n",
    "    if \"data\" in kwargs:\n",
    "        print(f\"MODEL OUTPUT: {kwargs['data']}\")\n",
    "    elif \"current_tool_use\" in kwargs and kwargs[\"current_tool_use\"].get(\"name\"):\n",
    "        print(f\"\\nUSING TOOL: {kwargs['current_tool_use']['name']}\")\n",
    "\n",
    "\n",
    "# Create an agent with custom callback handler\n",
    "agent = Agent(   \n",
    "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",  # Optional: Specify the model ID\n",
    "        tools=[calculator], \n",
    "        callback_handler=custom_callback_handler)\n",
    "\n",
    "agent(\"Calculate 2+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€éåŒæœŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã—ãŸã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
